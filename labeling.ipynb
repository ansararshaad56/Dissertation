{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87VMLflepT44",
        "outputId": "74a58b99-41f3-4453-9d02-0696497d77b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Cyberbullying_dataset.csv')\n",
        "\n",
        "# List of abusive words\n",
        "abusive_words = ['arsehole', 'asshat', 'asshole' ,'asholes','ashole','sucks','penis','sock','pupet','yal racist','lunatics', 'degre wil fake','hipocrite','big black cock' ,'bulshit', 'bitch', 'bloody' , 'bugger' ,'bullshit', 'chicken shit' , 'clusterfuck', 'cock', 'Cocksucker','cock sucker','sucker' , 'coonass','cornhole','coxâ€“zucker machine','cracker','cunt','dafuq','dick' , 'dickhead','faggot','feck','frak','fuck','fuck her right in the pussy','fuck Joe Biden','fuck' , 'marry',  'kill','fuckery','grab them by the pussy','healslut','motherfucker','neotrombicula fujigmo','nigga','nigger','paki' ,'slur','poof','poofter','porn' ,'prick','pussy','ratfucking','retard','russian warship', 'go fuck yourself','shit','shit happens','shithouse','shitter','shut the fuck up','slut','spic','tranny','twat','wanker','whore','arse','arsehead','arsehole','ass','asshole','bastard','bitch','bloody','bollocks','brotherfucker','bugger','bullshit','child-fucker','Christ on a bike','christ on a cracker','crap','damn','damn it','dyke','fatherfucker','frigger','goddamn','godamn','godsdamn','hell','horseshit','nazi','suni monkeys','kindgordon','darfur','gordon','suck phimos', 'nordicist','in shit','Jesus fuck','Jesus H. Christ','jesus Harold Christ','jesus wept','kike','motherfucker','nigra','pigfucker','piss','shit ass','shite','sisterfucker','son of a whore','son of a bitch','spastic','sweet Jesus','turd','twat','culver','dumbasales','screw lesbian', 'lesbian' ,'screw', 'pusy','ned get life','sockpupet', 'vandals', 'vandal', 'sick people','hated jews', 'idiot', 'moron']\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove emojis\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove repeating characters\n",
        "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Preprocess the text in the dataset\n",
        "data['Preprocessed_Text'] = data['Text'].apply(preprocess_text)\n",
        "\n",
        "# Function to label text as cyberbullying or not\n",
        "def label_cyberbullying(text):\n",
        "    for word in abusive_words:\n",
        "        if word in text:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "# Add the New_label column\n",
        "data['New_label'] = data['Preprocessed_Text'].apply(label_cyberbullying)\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "data.to_csv('labeled_dataset1.csv', index=False)"
      ],
      "metadata": {
        "id": "fCsK6mfN1tHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}