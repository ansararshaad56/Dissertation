# -*- coding: utf-8 -*-
"""labeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ltVz6MG71bzPTKbV9tQvv0tqSgtpnN-Y
"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')

import nltk
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Load the dataset
data = pd.read_csv('/content/Cyberbullying_dataset.csv')

# List of abusive words
abusive_words = ['arsehole', 'asshat', 'asshole' ,'asholes','ashole','sucks','penis','sock','pupet','yal racist','lunatics', 'degre wil fake','hipocrite','big black cock' ,'bulshit', 'bitch', 'bloody' , 'bugger' ,'bullshit', 'chicken shit' , 'clusterfuck', 'cock', 'Cocksucker','cock sucker','sucker' , 'coonass','cornhole','coxâ€“zucker machine','cracker','cunt','dafuq','dick' , 'dickhead','faggot','feck','frak','fuck','fuck her right in the pussy','fuck Joe Biden','fuck' , 'marry',  'kill','fuckery','grab them by the pussy','healslut','motherfucker','neotrombicula fujigmo','nigga','nigger','paki' ,'slur','poof','poofter','porn' ,'prick','pussy','ratfucking','retard','russian warship', 'go fuck yourself','shit','shit happens','shithouse','shitter','shut the fuck up','slut','spic','tranny','twat','wanker','whore','arse','arsehead','arsehole','ass','asshole','bastard','bitch','bloody','bollocks','brotherfucker','bugger','bullshit','child-fucker','Christ on a bike','christ on a cracker','crap','damn','damn it','dyke','fatherfucker','frigger','goddamn','godamn','godsdamn','hell','horseshit','nazi','suni monkeys','kindgordon','darfur','gordon','suck phimos', 'nordicist','in shit','Jesus fuck','Jesus H. Christ','jesus Harold Christ','jesus wept','kike','motherfucker','nigra','pigfucker','piss','shit ass','shite','sisterfucker','son of a whore','son of a bitch','spastic','sweet Jesus','turd','twat','culver','dumbasales','screw lesbian', 'lesbian' ,'screw', 'pusy','ned get life','sockpupet', 'vandals', 'vandal', 'sick people','hated jews', 'idiot', 'moron']

# Function to preprocess text
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()

    # Remove emojis
    text = re.sub(r'[^\w\s]', '', text)

    # Remove repeating characters
    text = re.sub(r'(.)\1+', r'\1', text)

    # Tokenize the text
    tokens = word_tokenize(text)

    # Remove stop words
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word not in stop_words]

    return ' '.join(filtered_tokens)

# Preprocess the text in the dataset
data['Preprocessed_Text'] = data['Text'].apply(preprocess_text)

# Function to label text as cyberbullying or not
def label_cyberbullying(text):
    for word in abusive_words:
        if word in text:
            return 1
    return 0

# Add the New_label column
data['New_label'] = data['Preprocessed_Text'].apply(label_cyberbullying)

# Save the updated dataset to a new CSV file
data.to_csv('labeled_dataset1.csv', index=False)